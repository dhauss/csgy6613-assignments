{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "aYvwc_wJFLrK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztN49YE-Ealh"
      },
      "outputs": [],
      "source": [
        "!pip install pytube ultralytics filterpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "U5qKkyD9FOlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import os\n",
        "import cv2\n",
        "from filterpy.kalman import KalmanFilter\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from google.colab import userdata\n",
        "# google patch for cv2.imshow\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "i3EwMwp8EtSq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Videos\n",
        "\n",
        "Convenience function which uses the PyTube API to download the YouTube videos specified in the assignment and store them in my Google Drive"
      ],
      "metadata": {
        "id": "vGu_-fvvFU9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_videos(video_id_list, output_path=\".\"):\n",
        "    \"\"\"\n",
        "    Download videos from YouTube based on a list of video IDs using PyTube API\n",
        "\n",
        "    Args:\n",
        "        video_id_list (list): A list of YouTube video IDs to download.\n",
        "        output_path (str, optional): The directory where the downloaded videos will be saved. Defaults to ./videos\n",
        "    \"\"\"\n",
        "    for video_id in video_id_list:\n",
        "      try:\n",
        "        yt = YouTube(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "        video = yt.streams.filter(file_extension='mp4', resolution='360p').first()\n",
        "        video.download(output_path)\n",
        "        print(f\"Video downloaded successfully: {yt.title}\")\n",
        "      except Exception as e:\n",
        "        print(f\"Error downloading video: {e}\")"
      ],
      "metadata": {
        "id": "xNeuSqQRFVlX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Video IDs specified in assignment\n",
        "video_id_list = [\"WeF4wpw7w9k\", \"2NFwY15tRtA\", \"5dRramZVu2Q\"]\n",
        "\n",
        "# Get current directory, define subdirectory for videos, and define full output path\n",
        "current_directory = os.getcwd()\n",
        "videos_directory = \"videos\"\n",
        "output_path = os.path.join(current_directory, videos_directory)\n",
        "\n",
        "# Join the current directory with the videos directory and download videos\n",
        "download_videos(video_id_list, output_path)\n",
        "\n",
        "# save all mp4 paths to video_paths list\n",
        "video_paths = []\n",
        "for root, dirs, files in os.walk(output_path):\n",
        "  for file in files:\n",
        "    full_path = os.path.join(root, file)\n",
        "    video_paths.append(full_path)\n",
        "\n",
        "# keep in sorted order for consistent IDs in PG instance\n",
        "video_paths.sort()\n",
        "\n",
        "for video_path in video_paths:\n",
        "  print(video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfZ-ClzZFaI5",
        "outputId": "d0523786-720a-4f48-91ab-815b1b8c684b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully: Cyclist and vehicle Tracking - 1\n",
            "Video downloaded successfully: Cyclist and vehicle tracking - 2\n",
            "Video downloaded successfully: Drone Tracking Video\n",
            "/content/videos/Cyclist and vehicle Tracking - 1.mp4\n",
            "/content/videos/Cyclist and vehicle tracking - 2.mp4\n",
            "/content/videos/Drone Tracking Video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Kalman Filter (50 points)\n",
        "\n",
        "Use the  [filterpy](https://filterpy.readthedocs.io/en/latest/kalman/KalmanFilter.html) library to implement Kalman filters that will track the cyclist and the vehicle (if present) in the video. You will need to use the detections from the previous task to initialize and run the Kalman filter.\n",
        "\n",
        "You need to deliver a video that contains the trajectory of the objects as a line that connects the pixels that the tracker indicated. You can use the `ffmpeg` command line tool and OpenCV to superpose the bounding box of the drone on the video as well as plot its trajectory.\n",
        "\n",
        "Suggest methods that you can use to address  false positives and how the tracker can help you in this regard.\n",
        "\n",
        "You will need to have one Kalman filter to track each of the required and present objects (cyclist and vehicle)."
      ],
      "metadata": {
        "id": "ZO2EA6AGFmKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(array_1, array_2):\n",
        "    \"\"\"\n",
        "    Compute the Euclidean distance between two 2D arrays.\n",
        "\n",
        "    Parameters:\n",
        "    array1 (numpy.ndarray): First 2D array.\n",
        "    array2 (numpy.ndarray): Second 2D array.\n",
        "\n",
        "    Returns:\n",
        "    float: Euclidean distance between the two arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute the squared differences between corresponding elements\n",
        "    squared_diff = (array_1 - array_2) ** 2\n",
        "\n",
        "    # Sum the squared differences along the last axis (assuming arrays are 2D)\n",
        "    squared_diff_sum = np.sum(squared_diff, axis=-1)\n",
        "\n",
        "    # Take the square root to get the Euclidean distance\n",
        "    distance = np.sqrt(squared_diff_sum)\n",
        "\n",
        "    return distance\n",
        "\n",
        "def find_nearest_neighbor(results, class_id, prev_pred):\n",
        "  tracked_car_centroids = []\n",
        "  ret_z = []\n",
        "  for result in results:\n",
        "    boxes = result.boxes\n",
        "    for box in boxes:\n",
        "      # check if detected object is a car object (class 1), if it is, add to list of tracked car centroids\n",
        "      if int(box.cls.item()) == class_id:\n",
        "        x, y, w, h = box.xywh[0].tolist()\n",
        "        cur_z = np.array([x + w/2, y + h/2])\n",
        "        if len(cur_z) > 1:\n",
        "          tracked_car_centroids.append(cur_z)\n",
        "\n",
        "  # find NN car, then update KF\n",
        "  min_dist = 999999999\n",
        "  for centroid in tracked_car_centroids:\n",
        "    dist_from_pred = euclidean_distance(centroid, prev_pred)\n",
        "    if dist_from_pred < min_dist:\n",
        "      min_dist = dist_from_pred\n",
        "      ret_z = centroid\n",
        "\n",
        "  return ret_z if len(ret_z) > 1 else prev_pred # return prev_pred if no cars detected\n",
        "\n",
        "def get_num_cars(results):\n",
        "  num_cars  = 0\n",
        "  for result in results:\n",
        "    boxes = result.boxes\n",
        "    for box in boxes:\n",
        "      # Check if detected object is a car object (class 1), if it is, add centroid. naive, but works because only one car is initially detected in this video\n",
        "      if int(box.cls.item() == 1):\n",
        "        num_cars += 1\n",
        "\n",
        "  return num_cars"
      ],
      "metadata": {
        "id": "lJpb6xCnQqKp"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_kalman_filter_vid1():\n",
        "    \"\"\"\n",
        "    Initialize Kalman Filter for an object moving initially upwards and towards the right,\n",
        "    but eventually turns and moves towards the top-left.\n",
        "\n",
        "    Returns:\n",
        "    KalmanFilter: Initialized Kalman Filter object.\n",
        "    \"\"\"\n",
        "    # Initialize Kalman Filter\n",
        "    kf = KalmanFilter(dim_x=6, dim_z=2)\n",
        "    kf.F = np.array([[1, 0, 1, 0, 0.5, 0],\n",
        "                     [0, 1, 0, 1, 0, 0.5],\n",
        "                     [0, 0, 1, 0, 1, 0],\n",
        "                     [0, 0, 0, 1, 0, 1],\n",
        "                     [0, 0, 0, 0, 1, 0],\n",
        "                     [0, 0, 0, 0, 0, 1]])\n",
        "    kf.H = np.array([[1, 0, 0, 0, 0, 0],\n",
        "                     [0, 1, 0, 0, 0, 0]])\n",
        "    kf.R = np.eye(2) * 0.01  # Measurement uncertainty\n",
        "\n",
        "    # Initial state vector [x, y, vx, vy, ax, ay]\n",
        "    # Assuming the object starts at the bottom-left corner and moves upwards and towards the right initially\n",
        "    kf.x = np.array([0, 500, 10, -10, 0, 0])\n",
        "\n",
        "    # Process uncertainty covariance matrix\n",
        "    kf.Q = np.array([[0.25, 0.5, 0, 0, 0, 0],\n",
        "                     [0.5, 1, 0, 0, 0, 0],\n",
        "                     [0, 0, 0.1, 0.2, 0, 0],\n",
        "                     [0, 0, 0.2, 0.4, 0, 0],\n",
        "                     [0, 0, 0, 0, 0.1, 0.2],\n",
        "                     [0, 0, 0, 0, 0.2, 0.4]])\n",
        "\n",
        "    return kf"
      ],
      "metadata": {
        "id": "HhGcN3OVFoym"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Video Results"
      ],
      "metadata": {
        "id": "6XgvFpMG7OYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLOv8 model\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/yolov8m_150_epochs_best.pt\"\n",
        "detection_model = YOLO(model_path)\n",
        "prev_pred = []\n",
        "kf = initialize_kalman_filter_vid1()\n",
        "car_id = 1\n",
        "\n",
        "video_path = video_paths[0]\n",
        "sample_rate = 10\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "# Variable to count frames\n",
        "frame_count = 0\n",
        "prev_pred = []\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "    cur_pred = []\n",
        "    z = []\n",
        "\n",
        "    if success:\n",
        "      # Increment the frame count\n",
        "      frame_count += 1\n",
        "\n",
        "      # Display every sample_rate'th frame\n",
        "      if frame_count % sample_rate == 0:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = detection_model(frame)\n",
        "\n",
        "        if(len(prev_pred) < 1 and len(results) < 1):  # Do nothing until first object is detected\n",
        "          continue\n",
        "        elif len(prev_pred) < 1:  # First detected results\n",
        "          for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "              # Check if detected object is a car object (class 1), if it is, add centroid. naive, but works because other objects leave z = []\n",
        "              if int(box.cls.item()) == car_id:\n",
        "                x, y, w, h = box.xywh[0].tolist()\n",
        "                z = np.array([x + w/2, y + h/2])\n",
        "        elif(len(results) < 1):\n",
        "          # display new predicted position based on old predicted position\n",
        "          z = prev_pred\n",
        "        else:\n",
        "          # update KF with position of NN and set prev_pred\n",
        "          z = find_nearest_neighbor(results, car_id, prev_pred)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        if len(z) > 0:\n",
        "          # Update Kalman Filter and generate prediction\n",
        "          kf.update(z)\n",
        "          kf.predict()\n",
        "          cur_pred = kf.x[:2]\n",
        "\n",
        "          # Extract coordinates from z and cur_pred\n",
        "          x_cur, y_cur = map(int, z)        # z coordinates\n",
        "          x_pred, y_pred = map(int, cur_pred) # predicted position\n",
        "\n",
        "          # reinitialize filter if predicted path goes off frame\n",
        "          if(x_pred > 352 or y_pred > 640 or x_pred < 0 or y_pred < 0):\n",
        "            kf = initialize_kalman_filter_vid1()\n",
        "\n",
        "          # Draw purple line from z to cur_pred\n",
        "          annotated_frame = cv2.line(annotated_frame, (x_cur, y_cur), (x_pred, y_pred), (255, 0, 255), 2)\n",
        "\n",
        "        # Display the annotated frame\n",
        "        cv2_imshow(annotated_frame)\n",
        "        prev_pred = cur_pred\n",
        "    else:\n",
        "      # Release the video capture object\n",
        "      cap.release()\n",
        "      # Break the loop if the end of the video is reached\n",
        "      break\n"
      ],
      "metadata": {
        "id": "w3RLh5s-Fq6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save mp4"
      ],
      "metadata": {
        "id": "Vq94IDikfOFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLOv8 model\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/yolov8m_150_epochs_best.pt\"\n",
        "detection_model = YOLO(model_path)\n",
        "prev_pred = []\n",
        "kf = initialize_kalman_filter_vid1()\n",
        "car_id = 1\n",
        "\n",
        "video_path = video_paths[0]\n",
        "output_video_path = \"/content/drive/MyDrive/Colab Notebooks/test_kf_results.mp4\"\n",
        "sample_rate = 1\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "# Get video frame dimensions\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, 30, (frame_width, frame_height))\n",
        "\n",
        "# Variable to count frames\n",
        "frame_count = 0\n",
        "prev_pred = []\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "    cur_pred = []\n",
        "    z =[]\n",
        "\n",
        "    if success:\n",
        "      # Increment the frame count\n",
        "      frame_count += 1\n",
        "\n",
        "      # Write every sample_rate'th frame\n",
        "      if frame_count % sample_rate == 0:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = detection_model(frame)\n",
        "\n",
        "        if(len(prev_pred) < 1 and len(results) < 1):  # Do nothing until first car object is detected\n",
        "          continue\n",
        "        elif len(prev_pred) < 1:  # First detected results\n",
        "          for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "              # Check if detected object is a car object (class 1), if it is, add centroid. naive, but works because only one car is initially detected in this video\n",
        "              if int(box.cls.item()) == car_id:\n",
        "                x, y, w, h = box.xywh[0].tolist()\n",
        "                z = np.array([x + w/2, y + h/2])\n",
        "        elif(len(results) < 1):\n",
        "          # display new predicted position based on old predicted position\n",
        "          z = prev_pred\n",
        "        else:\n",
        "          # set z to position of NN\n",
        "          z = find_nearest_neighbor(results, car_id, prev_pred)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        if len(z) > 0:\n",
        "          # Update Kalman Filter and generate prediction\n",
        "          kf.update(z)\n",
        "          kf.predict()\n",
        "          cur_pred = kf.x[:2]\n",
        "\n",
        "          # Extract coordinates from z and cur_pred\n",
        "          x_cur, y_cur = map(int, z)        # z coordinates\n",
        "          x_pred, y_pred = map(int, cur_pred) # predicted position\n",
        "\n",
        "          # reinitialize filter if predicted path goes off frame\n",
        "          if(x_pred > 352 or y_pred > 640 or x_pred < 0 or y_pred < 0):\n",
        "            kf = initialize_kalman_filter_vid1()\n",
        "\n",
        "          # Draw purple line from z to cur_pred\n",
        "          annotated_frame = cv2.line(annotated_frame, (x_cur, y_cur), (x_pred, y_pred), (255, 0, 255), 2)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        out.write(annotated_frame)\n",
        "\n",
        "        prev_pred = cur_pred\n",
        "    else:\n",
        "      # Release the video capture object and VideoWriter object\n",
        "      cap.release()\n",
        "      out.release()\n",
        "      break"
      ],
      "metadata": {
        "id": "wIb5CKU8fPtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Third Video Results"
      ],
      "metadata": {
        "id": "gCQrFWnM7T1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_kalman_filter_vid3():\n",
        "    \"\"\"\n",
        "    Initialize Kalman Filter for an object consistently moving from bottom-right to top-left.\n",
        "\n",
        "    Returns:\n",
        "    KalmanFilter: Initialized Kalman Filter object.\n",
        "    \"\"\"\n",
        "    # Initialize Kalman Filter\n",
        "    kf = KalmanFilter(dim_x=6, dim_z=2)\n",
        "    kf.F = np.array([[1, 0, -1, 0, 0.5, 0],\n",
        "                     [0, 1, 0, -1, 0, 0.5],\n",
        "                     [0, 0, 1, 0, 1, 0],\n",
        "                     [0, 0, 0, 1, 0, 1],\n",
        "                     [0, 0, 0, 0, 1, 0],\n",
        "                     [0, 0, 0, 0, 0, 1]])\n",
        "    kf.H = np.array([[1, 0, 0, 0, 0, 0],\n",
        "                     [0, 1, 0, 0, 0, 0]])\n",
        "    kf.R = np.eye(2) * 0.01  # Measurement uncertainty\n",
        "\n",
        "    # Initial state vector [x, y, vx, vy, ax, ay]\n",
        "    # Assuming the object starts at the bottom-right corner and moves towards the top-left\n",
        "    kf.x = np.array([640, 320, -10, -10, 0, 0])\n",
        "\n",
        "    # Process uncertainty covariance matrix\n",
        "    kf.Q = np.array([[0.25, 0.5, 0, 0, 0, 0],\n",
        "                     [0.5, 1, 0, 0, 0, 0],\n",
        "                     [0, 0, 0.1, 0.2, 0, 0],\n",
        "                     [0, 0, 0.2, 0.4, 0, 0],\n",
        "                     [0, 0, 0, 0, 0.1, 0.2],\n",
        "                     [0, 0, 0, 0, 0.2, 0.4]])\n",
        "\n",
        "    return kf"
      ],
      "metadata": {
        "id": "kM1zKbwN8Uka"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLOv8 model\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/yolov8m_150_epochs_best.pt\"\n",
        "detection_model = YOLO(model_path)\n",
        "prev_pred = []\n",
        "kf = initialize_kalman_filter_vid3()\n",
        "biker_id = 0\n",
        "\n",
        "video_path = video_paths[2]\n",
        "sample_rate = 10\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "# Variable to count frames\n",
        "frame_count = 0\n",
        "prev_pred = []\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "    cur_pred = []\n",
        "    z = []\n",
        "\n",
        "    if success:\n",
        "      # Increment the frame count\n",
        "      frame_count += 1\n",
        "\n",
        "      # Display every sample_rate'th frame\n",
        "      if frame_count % sample_rate == 0:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = detection_model(frame)\n",
        "\n",
        "        if(len(prev_pred) < 1 and len(results) < 1):  # Do nothing until first object is detected\n",
        "          continue\n",
        "        elif len(prev_pred) < 1:  # First detected results\n",
        "          for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "              # Check if detected object is a car object (class 1), if it is, add centroid. naive, but works because other objects leave z = []\n",
        "              if int(box.cls.item()) == biker_id:\n",
        "                x, y, w, h = box.xywh[0].tolist()\n",
        "                z = np.array([x + w/2, y + h/2])\n",
        "        elif(len(results) < 1):\n",
        "          # display new predicted position based on old predicted position\n",
        "          z = prev_pred\n",
        "        else:\n",
        "          # update KF with position of NN and set prev_pred\n",
        "          z = find_nearest_neighbor(results, biker_id, prev_pred)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        if len(z) > 0:\n",
        "          # Update Kalman Filter and generate prediction\n",
        "          kf.update(z)\n",
        "          kf.predict()\n",
        "          cur_pred = kf.x[:2]\n",
        "\n",
        "          # Extract coordinates from z and cur_pred\n",
        "          x_cur, y_cur = map(int, z)        # z coordinates\n",
        "          x_pred, y_pred = map(int, cur_pred) # predicted position\n",
        "\n",
        "          # reinitialize filter if predicted path goes off frame\n",
        "          if(x_pred > 352 or y_pred > 640 or x_pred < 0 or y_pred < 0):\n",
        "            kf = initialize_kalman_filter_vid1()\n",
        "\n",
        "          # Draw purple line from z to cur_pred\n",
        "          annotated_frame = cv2.line(annotated_frame, (x_cur, y_cur), (x_pred, y_pred), (255, 0, 255), 2)\n",
        "\n",
        "        # Display the annotated frame\n",
        "        cv2_imshow(annotated_frame)\n",
        "        prev_pred = cur_pred\n",
        "    else:\n",
        "      # Release the video capture object\n",
        "      cap.release()\n",
        "      # Break the loop if the end of the video is reached\n",
        "      break\n"
      ],
      "metadata": {
        "id": "-_E8pBPg7VV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLOv8 model\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/yolov8m_150_epochs_best.pt\"\n",
        "detection_model = YOLO(model_path)\n",
        "prev_pred = []\n",
        "kf = initialize_kalman_filter_vid3()\n",
        "biker_id = 0\n",
        "\n",
        "video_path = video_paths[2]\n",
        "output_video_path = \"/content/drive/MyDrive/Colab Notebooks/test2_kf_results.mp4\"\n",
        "sample_rate = 1\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "# Get video frame dimensions\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, 30, (frame_width, frame_height))\n",
        "\n",
        "# Variable to count frames\n",
        "frame_count = 0\n",
        "prev_pred = []\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "    cur_pred = []\n",
        "    z =[]\n",
        "\n",
        "    if success:\n",
        "      # Increment the frame count\n",
        "      frame_count += 1\n",
        "\n",
        "      # Write every sample_rate'th frame\n",
        "      if frame_count % sample_rate == 0:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = detection_model(frame)\n",
        "\n",
        "        if(len(prev_pred) < 1 and len(results) < 1):  # Do nothing until first car object is detected\n",
        "          continue\n",
        "        elif len(prev_pred) < 1:  # First detected results\n",
        "          for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "              # Check if detected object is a car object (class 1), if it is, add centroid. naive, but works because only one car is initially detected in this video\n",
        "              if int(box.cls.item()) == biker_id:\n",
        "                x, y, w, h = box.xywh[0].tolist()\n",
        "                z = np.array([x + w/2, y + h/2])\n",
        "        elif(len(results) < 1):\n",
        "          # display new predicted position based on old predicted position\n",
        "          z = prev_pred\n",
        "        else:\n",
        "          # set z to position of NN\n",
        "          z = find_nearest_neighbor(results, biker_id, prev_pred)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        if len(z) > 0:\n",
        "          # Update Kalman Filter and generate prediction\n",
        "          kf.update(z)\n",
        "          kf.predict()\n",
        "          cur_pred = kf.x[:2]\n",
        "\n",
        "          # Extract coordinates from z and cur_pred\n",
        "          x_cur, y_cur = map(int, z)        # z coordinates\n",
        "          x_pred, y_pred = map(int, cur_pred) # predicted position\n",
        "\n",
        "          # reinitialize filter if predicted path goes off frame\n",
        "          #if(x_pred > 352 or y_pred > 640 or x_pred < 0 or y_pred < 0):\n",
        "           # kf = initialize_kalman_filter_vid1()\n",
        "          if(x_pred > 35200 or y_pred > 64000 or x_pred < 0 or y_pred < 0):\n",
        "            kf = initialize_kalman_filter_vid1()\n",
        "\n",
        "          # Draw purple line from z to cur_pred\n",
        "          annotated_frame = cv2.line(annotated_frame, (x_cur, y_cur), (x_pred, y_pred), (255, 0, 255), 2)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        out.write(annotated_frame)\n",
        "\n",
        "        prev_pred = cur_pred\n",
        "    else:\n",
        "      # Release the video capture object and VideoWriter object\n",
        "      cap.release()\n",
        "      out.release()\n",
        "      break"
      ],
      "metadata": {
        "id": "_dRiD_hQ9r52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Bonus (20 points)\n",
        "\n",
        "```{eval-rst}\n",
        ".. youtube:: 2hQx48U1L-Y\n",
        "```\n",
        "\n",
        "The cyclist in the video goes in and out of occlusions. In addition the object is small making detections fairly problematic without finetuning and other optimizations.  Fintetuning involves using the pretrained model and training it further using images of cyclists from a training dataset such as [VisDrone](https://github.com/VisDrone/VisDrone-Dataset). At the same time,  reducing the number of classes to a much smaller number such as person & bicycle may help.  Also some 2 stage detectors may need to be further optimized in terms of parameters for small objects. See [this paper](https://www.mdpi.com/1424-8220/23/15/6887) for ideas around small object tracking.\n",
        "\n",
        "\n",
        "```{note}\n",
        "The extra points can only be awarded in the category of `assignments` and cannot be used to compensate for any other category such as `exams`.\n",
        "```"
      ],
      "metadata": {
        "id": "GpSMjecOFtZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the extra credit video using given video id\n",
        "ec_video_id = [\"2hQx48U1L-Y\"]\n",
        "download_videos(ec_video_id, output_path)\n",
        "# Save full video path\n",
        "ec_video_path = \"/content/videos/Dji Mavic air 2 drone using litchi app with follow me mode on a bike occluded by trees.mp4\"\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/yolov8m_150_epochs_best.pt\"\n",
        "detection_model = YOLO(model_path)\n",
        "prev_pred = []\n",
        "kf = initialize_kalman_filter_vid3()\n",
        "biker_id = 0\n",
        "\n",
        "video_path = ec_video_path\n",
        "output_video_path = \"/content/drive/MyDrive/Colab Notebooks/test3_kf_results.mp4\"\n",
        "sample_rate = 1\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "# Get video frame dimensions\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, 30, (frame_width, frame_height))\n",
        "\n",
        "# Variable to count frames\n",
        "frame_count = 0\n",
        "prev_pred = []\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "    cur_pred = []\n",
        "    z =[]\n",
        "\n",
        "    if success:\n",
        "      # Increment the frame count\n",
        "      frame_count += 1\n",
        "\n",
        "      # Write every sample_rate'th frame\n",
        "      if frame_count % sample_rate == 0:\n",
        "        # Run YOLOv8 inference on the frame\n",
        "        results = detection_model(frame)\n",
        "\n",
        "        if(len(prev_pred) < 1 and len(results) < 1):  # Do nothing until first car object is detected\n",
        "          continue\n",
        "        elif len(prev_pred) < 1:  # First detected results\n",
        "          for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "              # Check if detected object is a car object (class 1), if it is, add centroid. naive, but works because only one car is initially detected in this video\n",
        "              if int(box.cls.item()) == biker_id:\n",
        "                x, y, w, h = box.xywh[0].tolist()\n",
        "                z = np.array([x + w/2, y + h/2])\n",
        "        elif(len(results) < 1):\n",
        "          # display new predicted position based on old predicted position\n",
        "          z = prev_pred\n",
        "        else:\n",
        "          # set z to position of NN\n",
        "          z = find_nearest_neighbor(results, biker_id, prev_pred)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        if len(z) > 0:\n",
        "          # Update Kalman Filter and generate prediction\n",
        "          kf.update(z)\n",
        "          kf.predict()\n",
        "          cur_pred = kf.x[:2]\n",
        "\n",
        "          # Extract coordinates from z and cur_pred\n",
        "          x_cur, y_cur = map(int, z)        # z coordinates\n",
        "          x_pred, y_pred = map(int, cur_pred) # predicted position\n",
        "\n",
        "          # reinitialize filter if predicted path goes off frame\n",
        "          if(x_pred > 999999 or y_pred > 999999 or x_pred < -999999 or y_pred < -999999):\n",
        "           kf = initialize_kalman_filter_vid1()\n",
        "\n",
        "          # Draw purple line from z to cur_pred\n",
        "          annotated_frame = cv2.line(annotated_frame, (x_cur, y_cur), (x_pred, y_pred), (255, 0, 255), 2)\n",
        "\n",
        "        # Write the annotated frame to the output video\n",
        "        out.write(annotated_frame)\n",
        "\n",
        "        prev_pred = cur_pred\n",
        "    else:\n",
        "      # Release the video capture object and VideoWriter object\n",
        "      cap.release()\n",
        "      out.release()\n",
        "      break"
      ],
      "metadata": {
        "id": "kvWugDh0H_jv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}